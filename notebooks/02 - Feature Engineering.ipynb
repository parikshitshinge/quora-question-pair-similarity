{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Question Pair Similarity\n",
    "### Kaggle Competition link: https://www.kaggle.com/c/quora-question-pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our strategy for feature engineering is:\n",
    "0. Load raw & processed data\n",
    "1. Feature Engineering (on raw data - basic)\n",
    "2. EDA of new features\n",
    "3. Feature Engineering (on preprocessed data - thefuzz & raios)\n",
    "4. EDA of new features\n",
    "5. Feature Engineering (on processed data - TFIDF Weighted W2V)\n",
    "6. EDA of new features\n",
    "7. Combine all features \n",
    "8. Store the final features in sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports \n",
    "\n",
    "# General \n",
    "from datetime import datetime\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Data\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "# Feature engineering\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "#nltk.download('punkt')\n",
    "from thefuzz import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "\n",
    "# Database\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed.\n",
      "Time taken: 0:00:01.876207\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "# Read data\n",
    "raw_data = pd.read_csv(\"../data/raw/train.csv\", sep=\",\")\n",
    "\n",
    "# Processed data \n",
    "processed_data = pd.read_csv(\"../data/processed/processed_data.csv\", sep=\",\")\n",
    "\n",
    "print('Data loading completed.\\nTime taken: {0}'.format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1   \n",
       "0   0     1     2  What is the step by step guide to invest in sh...  \\\n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder math2324math divided 2423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1   \n",
       "0   0     1     2          step step guide invest share market india  \\\n",
       "1   1     3     4                    story kohinoor kohinoor diamond   \n",
       "2   2     5     6       increase speed internet connection using vpn   \n",
       "3   3     7     8                              mentally lonely solve   \n",
       "4   4     9    10  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0                step step guide invest share market             0  \n",
       "1  would happen indian government stole kohinoor ...             0  \n",
       "2               internet speed increased hacking dns             0  \n",
       "3           find remainder math2324math divided 2423             0  \n",
       "4                      fish would survive salt water             0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "processed_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Feature Engineering (on raw data)\n",
    "<li>q1_frequency = Frequency of Question1 in train corpus </li>\n",
    "<li>q2_frequency = Frequency of Question2 in train corpus </li>\n",
    "<li>q1_len = Length of Question1 </li>\n",
    "<li>q2_len = Length of Question2 </li>\n",
    "<li>q1_tokens_count = # of Tokens in Question1 </li>\n",
    "<li>q2_tokens_count = # of Tokens in Question2 </li>\n",
    "<li>q1_words_count = # of Words in Question1 </li>\n",
    "<li>q2_words_count = # of Words in Question2 </li>\n",
    "<li>q1_nonstopwords_count = # of Non-Stopwords in Question1 </li>\n",
    "<li>q2_nonstopwords_count = # of Non-Stopwords in Question2 </li>\n",
    "<li>common_tokens_count = # of Common Tokens in Question1 & Question2 </li>\n",
    "<li>common_tokens_share = (# of Common Tokens in Question1 & Question2) / (Total Tokens in Question1 & Question2) </li>\n",
    "<li>common_words_count = # of Common Words in Question1 & Question2 </li>\n",
    "<li>common_words_share = (# of Common Words in Question1 & Question2) / (Total Words in Question1 & Question2) </li>\n",
    "<li>common_nonstopwords_count = # of Common Non-Stopwords in Question1 & Question2 </li>\n",
    "<li>common_nonstopwords_share = (# of Common Non-Stopwords in Question1 & Question2) / (Total Non-Stopwords in Question1 & Question2) </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS.remove('not')\n",
    "\n",
    "def compute_common_tokens_count(row):\n",
    "    \"\"\"\n",
    "    Returns number of common tokens in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question1']) ))\n",
    "    t2 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question2']) ))  \n",
    "    return len(t1 & t2)\n",
    "\n",
    "def compute_common_tokens_share(row):\n",
    "    \"\"\"\n",
    "    Returns percentage of common tokens in Question1 & Question2 i.e. common tokens / total tokens\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question1']) ))\n",
    "    t2 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question2']) ))  \n",
    "    return len(t1 & t2) / (len(t1)+len(t2))\n",
    "\n",
    "def compute_common_words_count(row):\n",
    "    \"\"\"\n",
    "    Returns number of common words in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), row['question1'].split(\" \") ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), row['question2'].split(\" \") ))    \n",
    "    return len(w1 & w2)   \n",
    "\n",
    "def compute_common_words_share(row):\n",
    "    \"\"\"\n",
    "    Returns percentage of common words in Question1 & Question2 i.e. common words / total words\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), row['question1'].split(\" \") ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), row['question2'].split(\" \") ))    \n",
    "    return len(w1 & w2) / (len(w1) + len(w2))\n",
    "\n",
    "def compute_common_nonstopwords_count(row):\n",
    "    \"\"\"\n",
    "    Returns number of common nonstopwords in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question1'].split(\" \") if word not in STOPWORDS] ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question2'].split(\" \") if word not in STOPWORDS] ))    \n",
    "    return len(w1 & w2)    \n",
    "\n",
    "def compute_common_nonstopwords_share(row):\n",
    "    \"\"\"\n",
    "    Returns percentage of common nonstopwords in Question1 & Question2 i.e. common nonstopwords / total nonstopwords\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question1'].split(\" \") if word not in STOPWORDS] ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question2'].split(\" \") if word not in STOPWORDS] ))    \n",
    "    return len(w1 & w2) / (len(w1) + len(w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg_basic(df):\n",
    "    \"\"\"\n",
    "    Returns set of features:\n",
    "\tq1_frequency = Frequency of Question1 in train corpus \n",
    "\tq2_frequency = Frequency of Question2 in train corpus \n",
    "\tq1_len = Length of Question1 \n",
    "\tq2_len = Length of Question2 \n",
    "\tq1_tokens_count = # of Tokens in Question1 \n",
    "\tq2_tokens_count = # of Tokens in Question2 \n",
    "\tq1_words_count = # of Words in Question1 \n",
    "\tq2_words_count = # of Words in Question2 \n",
    "\tq1_nonstopwords_count = # of Non-Stopwords in Question1 \n",
    "\tq2_nonstopwords_count = # of Non-Stopwords in Question2 \n",
    "\tcommon_tokens_count = # of Common Tokens in Question1 & Question2 \n",
    "\tcommon_tokens_share = (# of Common Tokens in Question1 & Question2) / (Total Tokens in Question1 & Question2) \n",
    "\tcommon_words_count = # of Common Words in Question1 & Question2 \n",
    "\tcommon_words_share = (# of Common Words in Question1 & Question2) / (Total Words in Question1 & Question2) \n",
    "\tcommon_nonstopwords_count = # of Common Non-Stopwords in Question1 & Question2 \n",
    "\tcommon_nonstopwords_share = (# of Common Non-Stopwords in Question1 & Question2) / (Total Non-Stopwords in Question1 & Question2)     \n",
    "    \n",
    "    \"\"\"\n",
    "    # Convert all questions to string first\n",
    "    df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "    df['question2'] = df['question2'].apply(lambda x: str(x))\n",
    "    \n",
    "    # q1_frequency\n",
    "    start = datetime.now()\n",
    "    df['q1_frequency'] = df.groupby(by='qid1')['qid1'].transform('count')\n",
    "    print(\"Feature 'q1_frequency' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q2_frequency\n",
    "    start = datetime.now()\n",
    "    df['q2_frequency'] = df.groupby(by='qid2')['qid2'].transform('count')\n",
    "    print(\"Feature 'q2_frequency' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q1_length\n",
    "    start = datetime.now()\n",
    "    df['q1_length'] = df['question1'].str.len()\n",
    "    print(\"Feature 'q1_length' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q2_length\n",
    "    start = datetime.now()\n",
    "    df['q2_length'] = df['question2'].str.len()\n",
    "    print(\"Feature 'q2_length' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q1_tokens_count\n",
    "    start = datetime.now()\n",
    "    df['q1_tokens_count'] = df['question1'].apply(lambda x: len(word_tokenize(x)))\n",
    "    print(\"Feature 'q1_tokens_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q2_tokens_count\n",
    "    start = datetime.now()\n",
    "    df['q2_tokens_count'] = df['question2'].apply(lambda x: len(word_tokenize(x)))\n",
    "    print(\"Feature 'q2_tokens_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "\n",
    "    # q1_words_count\n",
    "    start = datetime.now()\n",
    "    df['q1_words_count'] = df['question1'].apply(lambda x: len(x.split(\" \")))\n",
    "    print(\"Feature 'q1_words_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "\n",
    "    # q2_words_count\n",
    "    start = datetime.now()\n",
    "    df['q2_words_count'] = df['question2'].apply(lambda x: len(x.split(\" \")))\n",
    "    print(\"Feature 'q2_words_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q1_nonstopwords_count\n",
    "    start = datetime.now()\n",
    "    df['q1_nonstopwords_count'] = df['question1'].apply(lambda x: len([word for word in str.lower(x).split(\" \") if word not in STOPWORDS]))\n",
    "    print(\"Feature 'q1_nonstopwords_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # q2_nonstopwords_count\n",
    "    start = datetime.now()\n",
    "    df['q2_nonstopwords_count'] = df['question2'].apply(lambda x: len([word for word in str.lower(x).split(\" \") if word not in STOPWORDS]))   \n",
    "    print(\"Feature 'q2_nonstopwords_count' created. Time taken: {0}\".format(datetime.now() - start)) \n",
    "    \n",
    "    # common_tokens_count\n",
    "    start = datetime.now()\n",
    "    df['common_tokens_count'] =  df.apply(compute_common_tokens_count, axis=1)\n",
    "    print(\"Feature 'common_tokens_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_tokens_share\n",
    "    start = datetime.now()\n",
    "    df['common_tokens_share'] =  df.apply(compute_common_tokens_share, axis=1)\n",
    "    print(\"Feature 'common_tokens_share' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_words_count\n",
    "    start = datetime.now()\n",
    "    df['common_words_count'] =  df.apply(compute_common_words_count, axis=1)\n",
    "    print(\"Feature 'common_words_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "        \n",
    "    # common_words_share\n",
    "    start = datetime.now()\n",
    "    df['common_words_share'] =  df.apply(compute_common_words_share, axis=1)\n",
    "    print(\"Feature 'common_words_share' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_nonstopwords_count\n",
    "    start = datetime.now()\n",
    "    df['common_nonstopwords_count'] =  df.apply(compute_common_nonstopwords_count, axis=1)\n",
    "    print(\"Feature 'common_nonstopwords_count' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_nonstopwords_share\n",
    "    start = datetime.now()\n",
    "    df['common_nonstopwords_share'] =  df.apply(compute_common_nonstopwords_share, axis=1)\n",
    "    print(\"Feature 'common_nonstopwords_share' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_featurized = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering on raw_data started!\n",
      "Feature 'q1_frequency' created. Time taken: 0:00:00.076525\n",
      "Feature 'q2_frequency' created. Time taken: 0:00:00.056018\n",
      "Feature 'q1_length' created. Time taken: 0:00:00.100526\n",
      "Feature 'q2_length' created. Time taken: 0:00:00.117523\n",
      "Feature 'q1_tokens_count' created. Time taken: 0:00:38.699519\n",
      "Feature 'q2_tokens_count' created. Time taken: 0:00:40.492525\n",
      "Feature 'q1_words_count' created. Time taken: 0:00:00.373136\n",
      "Feature 'q2_words_count' created. Time taken: 0:00:00.385225\n",
      "Feature 'q1_nonstopwords_count' created. Time taken: 0:00:00.931859\n",
      "Feature 'q2_nonstopwords_count' created. Time taken: 0:00:00.926097\n",
      "Feature 'common_tokens_count' created. Time taken: 0:01:34.755135\n",
      "Feature 'common_tokens_share' created. Time taken: 0:01:54.588778\n",
      "Feature 'common_words_count' created. Time taken: 0:00:07.703769\n",
      "Feature 'common_words_share' created. Time taken: 0:00:07.634031\n",
      "Feature 'common_nonstopwords_count' created. Time taken: 0:00:07.646243\n",
      "Feature 'common_nonstopwords_share' created. Time taken: 0:00:07.768633\n",
      "Feature engineering on raw_data completed!\n",
      "\n",
      "Total time taken: 0:05:22.256548\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../data/processed/raw_data_featurized.csv\"):\n",
    "    print('Featurized data already available. Getting it from the disk...')\n",
    "    raw_data_featurized = pd.read_csv(\"../data/processed/raw_data_featurized.csv\", sep=\",\", encoding='latin-1')\n",
    "    raw_data_featurized.fillna(\"\")\n",
    "    print('Data loaded!')\n",
    "else:\n",
    "    start = datetime.now()\n",
    "    print(\"Feature engineering on raw_data started!\")\n",
    "    feature_engg_basic(raw_data_featurized)\n",
    "    print(\"Feature engineering on raw_data completed!\\n\\nTotal time taken: {0}\".format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw_data: (404290, 6)\n",
      "Shape of raw_data_featurized: (404290, 22)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of raw_data: {0}'.format(raw_data.shape))\n",
    "print('Shape of raw_data_featurized: {0}'.format(raw_data_featurized.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data_featurized exported!\n"
     ]
    }
   ],
   "source": [
    "# Export raw_data_featurized to csv\n",
    "raw_data_featurized.to_csv('../data/processed/raw_data_featurized.csv', index=False)\n",
    "print('raw_data_featurized exported!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature Engineering (on processed data)\n",
    "Here we will use the library thefuzz (https://github.com/seatgeek/thefuzz) to generate features and we will also use some advanced ratios:\n",
    "\n",
    "<li>Fuzz ratio </li>\n",
    "<li>Fuzz partial ratio </li>\n",
    "<li>Fuzz token sort ratio </li>\n",
    "<li>Fuzz token set ratio </li>\n",
    "<li>Fuzz partial token sort ratio </li>\n",
    "\n",
    "\n",
    "<li>common_tokens_count_min = (# of Common Tokens in Question1 & Question2) / MIN(Total Tokens in Question1, Total Tokens in Question2) </li>\n",
    "<li>common_tokens_count_max = (# of Common Tokens in Question1 & Question2) / MAX(Total Tokens in Question1, Total Tokens in Question2) </li>\n",
    "<li>common_words_count_min = (# of Common Words in Question1 & Question2) / MIN(Total Words in Question1,Total Words in Question2) </li>\n",
    "<li>common_words_count_max = (# of Common Words in Question1 & Question2) / MAX(Total Words in Question1, Total Words in Question2) </li>\n",
    "<li>common_nonstopwords_count_min = (# of Common Non-Stopwords in Question1 & Question2) / MIN(Total Non-Stopwords in Question1, Total Non-Stopwords in Question2) </li>\n",
    "<li>common_nonstopwords_count_max = (# of Common Non-Stopwords in Question1 & Question2) / MAX(Total Non-Stopwords in Question1, Total Non-Stopwords in Question2) </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "STOPWORDS.remove('not')\n",
    "\n",
    "SAFE_DIVISION = 0.0001\n",
    "\n",
    "def compute_common_tokens_count_min(row):\n",
    "    \"\"\"\n",
    "    Returns number of common tokens in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question1']) ))\n",
    "    t2 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question2']) ))  \n",
    "    return len(t1 & t2) / (min(len(t1), len(t2)) + SAFE_DIVISION)\n",
    "\n",
    "def compute_common_tokens_count_max(row):\n",
    "    \"\"\"\n",
    "    Returns number of common tokens in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question1']) ))\n",
    "    t2 = set(map(lambda word: str(word).lower().strip(), word_tokenize(row['question2']) ))  \n",
    "    return len(t1 & t2) / (max(len(t1), len(t2)) + SAFE_DIVISION)\n",
    "\n",
    "\n",
    "def compute_common_words_count_min(row):\n",
    "    \"\"\"\n",
    "    Returns number of common words in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), row['question1'].split(\" \") ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), row['question2'].split(\" \") ))    \n",
    "    return len(w1 & w2) / (min(len(w1), len(w2)) + SAFE_DIVISION)\n",
    "\n",
    "def compute_common_words_count_max(row):\n",
    "    \"\"\"\n",
    "    Returns number of common words in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), row['question1'].split(\" \") ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), row['question2'].split(\" \") ))    \n",
    "    return len(w1 & w2) / (max(len(w1), len(w2)) + SAFE_DIVISION)\n",
    "\n",
    "def compute_common_nonstopwords_count_min(row):\n",
    "    \"\"\"\n",
    "    Returns number of common nonstopwords in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question1'].split(\" \") if word not in STOPWORDS] ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question2'].split(\" \") if word not in STOPWORDS] ))    \n",
    "    return len(w1 & w2) / (min(len(w1), len(w2)) + SAFE_DIVISION)\n",
    "\n",
    "def compute_common_nonstopwords_count_max(row):\n",
    "    \"\"\"\n",
    "    Returns number of common nonstopwords in Question1 & Question2\n",
    "    \n",
    "    \"\"\"\n",
    "    w1 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question1'].split(\" \") if word not in STOPWORDS] ))\n",
    "    w2 = set(map(lambda word: str(word).lower().strip(), [word for word in row['question2'].split(\" \") if word not in STOPWORDS] ))    \n",
    "    return len(w1 & w2) / (max(len(w1), len(w2)) + SAFE_DIVISION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engg_adv(df):\n",
    "    \"\"\"\n",
    "    Returns set of features:\n",
    "    fuzz_ratio \n",
    "    fuzz_partial_ratio \n",
    "    fuzz_token_sort_ratio \n",
    "    fuzz_token_set_ratio \n",
    "    fuzz_partial_token_sort_ratio \n",
    "    common_tokens_count_min = (# of Common Tokens in Question1 & Question2) / MIN(Total Tokens in Question1, Total Tokens in Question2) \n",
    "    common_tokens_count_max = (# of Common Tokens in Question1 & Question2) / MAX(Total Tokens in Question1, Total Tokens in Question2) \n",
    "    common_words_count_min = (# of Common Words in Question1 & Question2) / MIN(Total Words in Question1,Total Words in Question2) \n",
    "    common_words_count_max = (# of Common Words in Question1 & Question2) / MAX(Total Words in Question1, Total Words in Question2) \n",
    "    common_nonstopwords_count_min = (# of Common Non-Stopwords in Question1 & Question2) / MIN(Total Non-Stopwords in Question1, Total Non-Stopwords in Question2) \n",
    "    common_nonstopwords_count_max = (# of Common Non-Stopwords in Question1 & Question2) / MAX(Total Non-Stopwords in Question1, Total Non-Stopwords in Question2) \n",
    "    \n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    \n",
    "    # Convert all questions to string\n",
    "    df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "    df['question2'] = df['question2'].apply(lambda x: str(x))\n",
    "    \n",
    "    # fuzz_ratio\n",
    "    start = datetime.now()\n",
    "    df['fuzz_ratio'] = df.apply(lambda x: fuzz.ratio(x['question1'], x['question2']), axis=1 )\n",
    "    print(\"Feature 'fuzz_ratio' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # fuzz_partial_ratio\n",
    "    start = datetime.now()\n",
    "    df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(x['question1'], x['question2']), axis=1 )\n",
    "    print(\"Feature 'fuzz_partial_ratio' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # fuzz_token_sort_ratio\n",
    "    start = datetime.now()\n",
    "    df['fuzz_token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(x['question1'], x['question2']), axis=1 )\n",
    "    print(\"Feature 'fuzz_token_sort_ratio' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # fuzz_token_set_ratio\n",
    "    start = datetime.now()\n",
    "    df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(x['question1'], x['question2']), axis=1 )\n",
    "    print(\"Feature 'fuzz_token_set_ratio' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "\n",
    "    # fuzz_partial_token_sort_ratio\n",
    "    start = datetime.now()\n",
    "    df['fuzz_partial_token_sort_ratio'] = df.apply(lambda x: fuzz.partial_token_sort_ratio(x['question1'], x['question2']), axis=1 )\n",
    "    print(\"Feature 'fuzz_partial_token_sort_ratio' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_tokens_count_min\n",
    "    start = datetime.now()\n",
    "    df['common_tokens_count_min'] =  df.apply(compute_common_tokens_count_min, axis=1)\n",
    "    print(\"Feature 'common_tokens_count_min' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_tokens_count_max\n",
    "    start = datetime.now()\n",
    "    df['common_tokens_count_max'] =  df.apply(compute_common_tokens_count_max, axis=1)\n",
    "    print(\"Feature 'common_tokens_count_max' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_words_count_min\n",
    "    start = datetime.now()\n",
    "    df['common_words_count_min'] =  df.apply(compute_common_words_count_min, axis=1)\n",
    "    print(\"Feature 'common_words_count_min' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "        \n",
    "    # common_words_count_max\n",
    "    start = datetime.now()\n",
    "    df['common_words_count_max'] =  df.apply(compute_common_words_count_max, axis=1)\n",
    "    print(\"Feature 'common_words_count_max' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_nonstopwords_count_min\n",
    "    start = datetime.now()\n",
    "    df['common_nonstopwords_count_min'] =  df.apply(compute_common_nonstopwords_count_min, axis=1)\n",
    "    print(\"Feature 'common_nonstopwords_count_min' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    # common_nonstopwords_count_max\n",
    "    start = datetime.now()\n",
    "    df['common_nonstopwords_count_max'] =  df.apply(compute_common_nonstopwords_count_max, axis=1)\n",
    "    print(\"Feature 'common_nonstopwords_count_max' created. Time taken: {0}\".format(datetime.now() - start))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_featurized = processed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering on processed_data started!\n",
      "Feature 'fuzz_ratio' created. Time taken: 0:00:37.170625\n",
      "Feature 'fuzz_partial_ratio' created. Time taken: 0:03:38.835334\n",
      "Feature 'fuzz_token_sort_ratio' created. Time taken: 0:00:56.323212\n",
      "Feature 'fuzz_token_set_ratio' created. Time taken: 0:01:16.347247\n",
      "Feature 'fuzz_partial_token_sort_ratio' created. Time taken: 0:04:07.361945\n",
      "Feature 'common_tokens_count_min' created. Time taken: 0:01:13.918511\n",
      "Feature 'common_tokens_count_max' created. Time taken: 0:01:14.509648\n",
      "Feature 'common_words_count_min' created. Time taken: 0:00:06.311327\n",
      "Feature 'common_words_count_max' created. Time taken: 0:00:06.898898\n",
      "Feature 'common_nonstopwords_count_min' created. Time taken: 0:00:08.161611\n",
      "Feature 'common_nonstopwords_count_max' created. Time taken: 0:00:07.421651\n",
      "Feature engineering on processed_data completed!\n",
      "\n",
      "Total time taken: 0:13:33.516169\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../data/processed/processed_data_featurized.csv\"):\n",
    "    print('Featurized data already available. Getting it from the disk...')\n",
    "    processed_data_featurized = pd.read_csv(\"../data/processed/processed_data_featurized.csv\", sep=\",\", encoding='latin-1')\n",
    "    processed_data_featurized.fillna(\"\")\n",
    "    print('Data loaded!')\n",
    "else:\n",
    "    start = datetime.now()\n",
    "    print(\"Feature engineering on processed_data started!\")\n",
    "    feature_engg_adv(processed_data_featurized)\n",
    "    print(\"Feature engineering on processed_data completed!\\n\\nTotal time taken: {0}\".format(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of processed_data: (404290, 7)\n",
      "Shape of processed_data_featurized: (404290, 17)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of processed_data: {0}'.format(processed_data.shape))\n",
    "print('Shape of processed_data_featurized: {0}'.format(processed_data_featurized.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_data_featurized exported!\n"
     ]
    }
   ],
   "source": [
    "# Export processed_data_featurized to csv\n",
    "processed_data_featurized.to_csv('../data/processed/processed_data_featurized.csv', index=False)\n",
    "print('processed_data_featurized exported!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Engineering (on processed data - TFIDF Weighted W2V)\n",
    "\n",
    "Here, we will convert each question into a 300 dimensional vector using below strategy:<br>\n",
    "1. For each question, we will compute its TF-IDF value for each word\n",
    "2. We will use a pre-trained model (GloVe) to get W2V vector of each word\n",
    "3. For each question, we will element wise multiplication of all words' TF-IDF values by its W2V value and then divide its sum by sum of all word's TF-IDF values <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words are vectorized using TFIDF.\n",
      "\n",
      "Time taken: 0:00:05.156417\n"
     ]
    }
   ],
   "source": [
    "# Compute TF-IDF for all words in all the questions\n",
    "questions = list(processed_data['question1']) + list(processed_data['question2'])\n",
    "questions = [x for x in questions if pd.notnull(x)]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False)\n",
    "tfidf.fit_transform(questions)\n",
    "print('All words are vectorized using TFIDF.\\n\\nTime taken: {0}'.format(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the words and their TF IDF values in dictionary\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.443780468237108"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2tfidf['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GloVe model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vector: 300\n",
      "Vector: [ -1.2867    -0.7992    -2.092     -0.77679   -2.5057     2.7123\n",
      "   0.59127    3.2927    -1.5826     6.4515     1.3452    -1.9711\n",
      "   0.93059    2.8943     4.2116     1.6        2.6821    -8.4476\n",
      "   2.3301     6.0751    -0.39937    7.3433    -2.2546    -5.9357\n",
      "   3.6748    -4.9191    -3.1941    -4.2882     3.4951    -3.1585\n",
      "   0.69749    0.48132   -0.6059     0.22147   -2.9045     0.27525\n",
      "  -6.0088     5.0995    -3.367      2.6089    -5.6207    -2.6762\n",
      "   6.0931     3.1168     3.2641    -4.0576    -4.435      1.4214\n",
      "   0.59049    8.941      2.0718     5.3188     2.8866     0.0945\n",
      "  -0.25755    0.93984    7.9412    -2.2701    -0.65029    1.4952\n",
      "  -2.5503    -3.7978    -5.853     -1.7847     1.4484    -3.9781\n",
      "  -1.3968   -10.793     -4.5546    -0.12542    4.4986     1.7492\n",
      "   0.50073   -1.1922     2.0405    -2.1606    -1.5879    10.005\n",
      "   1.5086    -2.7168    -1.2617    -2.1364     1.2624    -4.1934\n",
      "   0.87337    2.2741    -1.8725     4.7847    -0.19699    0.49063\n",
      "   1.676     -7.2461     8.69      -6.7596     1.4258    -1.3082\n",
      "   0.49451    1.0113     4.8767    -8.7557     5.7198    -3.9122\n",
      "   2.9248    -3.0411    -4.9627    -4.62      -3.115      0.41967\n",
      "   0.28133    0.12302   -4.0926     1.08       0.29599    2.3666\n",
      "   6.8539     2.5459    -1.9408    -2.887      0.30666    2.3324\n",
      "  -0.069124  -3.6478    -8.6565     3.3408    -1.6408    -4.1846\n",
      "   9.567      0.91341    5.7761     4.2719     2.5493    -3.2469\n",
      "   7.7067    -3.1646     0.11333    4.4113    -1.8485     0.41425\n",
      "   2.8236     5.334    -11.2       -4.0501     3.2927     2.133\n",
      "  -1.3271    -5.1098    -8.8281     1.9037    -2.9818    -0.65455\n",
      "   5.1407    -1.3194     0.39336   -0.028404  -1.1846     3.8982\n",
      "   4.3978    -1.2017    -7.2908    -3.216      1.4994    -8.3424\n",
      "  -2.7203     5.5298    -3.8797    -1.7302     1.7454     1.1949\n",
      "   1.6159     0.80036    1.5803     6.8892     2.2089     4.0075\n",
      "   4.5673    -2.8403    -1.5487     2.1561    -3.5629    -6.9477\n",
      "   3.1076    -4.0521     5.3745     0.56936   -0.87056    0.46465\n",
      "   2.8535     0.41045    2.2412    -1.7558     0.7084     3.3363\n",
      "  -0.1505     2.0362    -0.53224   -3.1957    -0.13258    9.3884\n",
      "  -3.4061     1.4806     8.1324    -0.59143   -4.9386     1.9289\n",
      "  -5.3873    -0.85809   -2.5       -8.0451    -4.7292    -7.2426\n",
      "  -1.4862     0.98244   -4.1294     2.9509    -2.347      2.4539\n",
      "   0.94502    5.6181    -2.6881    -2.3321     3.1072    -4.4747\n",
      "   6.6671     7.2443    -1.4954    -1.5245    -1.8482     2.0941\n",
      "   5.8111    -5.1892    -2.4437    -3.8453    -1.4752    -2.7762\n",
      "  -3.46       2.761     -8.0596     4.1683    -3.9315     1.3891\n",
      "   1.072     -0.285      6.1694    -3.0699     1.1224    -6.0554\n",
      "   1.9909     0.44939    3.9851     2.0694     1.086     -4.5804\n",
      "  -3.5417     1.7268    -2.1781     8.1669     3.8169     6.0367\n",
      "  -2.2298     2.9053     3.1637     0.33807   -1.534     -0.76545\n",
      "  -0.4528    -1.8763     2.8293    -1.591     -4.7978     2.5972\n",
      "   4.0572    -1.3079    -7.5431     1.551     -0.17833   -3.5017\n",
      "   2.5796     0.80785   -6.4167    12.792     -6.1626    -4.375\n",
      "   2.9925     2.4804     8.1384    -1.7968    -2.4738     0.2149\n",
      "  -2.8114    -1.0245     3.9408    -1.972      0.072622  -2.5904\n",
      "  -1.439     -3.3312     4.8377     8.8206     0.18837    2.7038  ]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "x=nlp(\"man\")\n",
    "print(\"Length of vector: {0}\".format(len(x.vector)))\n",
    "print(\"Vector: {0}\".format(x.vector))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert question1 & question2 to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf_avg_w2v(question):\n",
    "    question = str(question)\n",
    "        \n",
    "    question_nlp = nlp(question)\n",
    "    avg_vector = np.zeros([len(question_nlp), len(question_nlp[0].vector)]) # Initialize the mean vector with 0s\n",
    "    \n",
    "    for word in question_nlp:\n",
    "        word_vector = word.vector\n",
    "        try:\n",
    "            idf = word2tfidf[str(word)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        avg_vector += word_vector * idf\n",
    "    return avg_vector.mean(axis=0)\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_tfidfavgw2v = processed_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing TFIDF Avg. W2V for Question1\n",
      "Completed!\n",
      "Time taken: 0:38:07.884703\n",
      "Computing TFIDF Avg. W2V for Question1\n",
      "Completed!\n",
      "Time taken: 0:39:23.286483\n"
     ]
    }
   ],
   "source": [
    "# Check if features are already saved in disk. If yes, load it from disk, else regrenerate.\n",
    "\n",
    "if os.path.isfile(\"../data/processed/q1_tfidfavgw2v_features.csv\"):\n",
    "    print('Featurized data already available. Getting it from the disk...')\n",
    "    q1_tfidfavgw2v_features = pd.read_csv(\"../data/processed/q1_tfidfavgw2v_features.csv\", sep=\",\", encoding='latin-1')\n",
    "    q1_tfidfavgw2v_features.fillna(\"\")\n",
    "    print('Data loaded!')\n",
    "else:\n",
    "    start = datetime.now()\n",
    "    print(\"Computing TFIDF Avg. W2V for Question1\")\n",
    "    processed_data_tfidfavgw2v['q1_tfidfavgw2v_features'] = processed_data_tfidfavgw2v['question1'].apply(compute_tfidf_avg_w2v)\n",
    "    print(\"Completed!\\nTime taken: {0}\".format(datetime.now() - start))\n",
    "    q1_tfidfavgw2v_features = pd.DataFrame(processed_data_tfidfavgw2v['q1_tfidfavgw2v_features'].values.tolist(), index=processed_data_tfidfavgw2v.index)\n",
    "\n",
    "\n",
    "if os.path.isfile(\"../data/processed/q2_tfidfavgw2v_features.csv\"):\n",
    "    print('Featurized data already available. Getting it from the disk...')\n",
    "    q2_tfidfavgw2v_features = pd.read_csv(\"../data/processed/q2_tfidfavgw2v_features.csv\", sep=\",\", encoding='latin-1')\n",
    "    q2_tfidfavgw2v_features.fillna(\"\")\n",
    "    print('Data loaded!')\n",
    "else:\n",
    "    start = datetime.now()\n",
    "    print(\"Computing TFIDF Avg. W2V for Question1\")\n",
    "    processed_data_tfidfavgw2v['q2_tfidfavgw2v_features'] = processed_data_tfidfavgw2v['question2'].apply(compute_tfidf_avg_w2v)\n",
    "    print(\"Completed!\\nTime taken: {0}\".format(datetime.now() - start))\n",
    "    q2_tfidfavgw2v_features = pd.DataFrame(processed_data_tfidfavgw2v['q2_tfidfavgw2v_features'].values.tolist(), index=processed_data_tfidfavgw2v.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of q1_tfidfavgw2v_features: (404290, 300)\n",
      "Shape of q2_tfidfavgw2v_features: (404290, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of q1_tfidfavgw2v_features: {0}\".format(q1_tfidfavgw2v_features.shape))\n",
    "print(\"Shape of q2_tfidfavgw2v_features: {0}\".format(q2_tfidfavgw2v_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.973457</td>\n",
       "      <td>44.453701</td>\n",
       "      <td>-173.219830</td>\n",
       "      <td>-4.410628</td>\n",
       "      <td>75.493393</td>\n",
       "      <td>41.393043</td>\n",
       "      <td>-41.580649</td>\n",
       "      <td>84.183355</td>\n",
       "      <td>-278.957716</td>\n",
       "      <td>23.654842</td>\n",
       "      <td>...</td>\n",
       "      <td>26.416055</td>\n",
       "      <td>-84.681734</td>\n",
       "      <td>-88.431000</td>\n",
       "      <td>37.586479</td>\n",
       "      <td>4.812845</td>\n",
       "      <td>-50.764075</td>\n",
       "      <td>-21.439394</td>\n",
       "      <td>-47.322849</td>\n",
       "      <td>-114.611610</td>\n",
       "      <td>-0.633502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.109793</td>\n",
       "      <td>2.340805</td>\n",
       "      <td>-21.485545</td>\n",
       "      <td>-59.833237</td>\n",
       "      <td>25.337529</td>\n",
       "      <td>-48.522722</td>\n",
       "      <td>20.918352</td>\n",
       "      <td>88.404150</td>\n",
       "      <td>-18.247384</td>\n",
       "      <td>0.922639</td>\n",
       "      <td>...</td>\n",
       "      <td>18.760534</td>\n",
       "      <td>28.946899</td>\n",
       "      <td>40.868272</td>\n",
       "      <td>41.995686</td>\n",
       "      <td>-16.039801</td>\n",
       "      <td>-6.515951</td>\n",
       "      <td>17.120571</td>\n",
       "      <td>4.826173</td>\n",
       "      <td>-36.251713</td>\n",
       "      <td>-4.849846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-46.598287</td>\n",
       "      <td>26.098580</td>\n",
       "      <td>-58.658402</td>\n",
       "      <td>62.726847</td>\n",
       "      <td>51.278867</td>\n",
       "      <td>-51.657226</td>\n",
       "      <td>61.282318</td>\n",
       "      <td>218.317215</td>\n",
       "      <td>-145.487613</td>\n",
       "      <td>51.764659</td>\n",
       "      <td>...</td>\n",
       "      <td>16.600708</td>\n",
       "      <td>10.613136</td>\n",
       "      <td>44.777887</td>\n",
       "      <td>13.170672</td>\n",
       "      <td>-40.014347</td>\n",
       "      <td>90.090577</td>\n",
       "      <td>110.328283</td>\n",
       "      <td>-130.407567</td>\n",
       "      <td>-71.836666</td>\n",
       "      <td>49.603967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.360342</td>\n",
       "      <td>60.163725</td>\n",
       "      <td>-27.901776</td>\n",
       "      <td>-53.709725</td>\n",
       "      <td>-35.968431</td>\n",
       "      <td>24.307124</td>\n",
       "      <td>47.461727</td>\n",
       "      <td>82.214472</td>\n",
       "      <td>-20.191026</td>\n",
       "      <td>8.705730</td>\n",
       "      <td>...</td>\n",
       "      <td>40.188845</td>\n",
       "      <td>-64.445338</td>\n",
       "      <td>3.300989</td>\n",
       "      <td>-3.460388</td>\n",
       "      <td>-5.688108</td>\n",
       "      <td>-39.654131</td>\n",
       "      <td>-8.501600</td>\n",
       "      <td>41.287611</td>\n",
       "      <td>-22.826380</td>\n",
       "      <td>72.295970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.598532</td>\n",
       "      <td>-100.970966</td>\n",
       "      <td>-192.003554</td>\n",
       "      <td>32.115457</td>\n",
       "      <td>105.654387</td>\n",
       "      <td>-244.451265</td>\n",
       "      <td>0.215317</td>\n",
       "      <td>295.835997</td>\n",
       "      <td>140.651610</td>\n",
       "      <td>-64.710206</td>\n",
       "      <td>...</td>\n",
       "      <td>53.694146</td>\n",
       "      <td>-93.960855</td>\n",
       "      <td>280.227130</td>\n",
       "      <td>-71.913438</td>\n",
       "      <td>-244.190637</td>\n",
       "      <td>108.494457</td>\n",
       "      <td>354.313131</td>\n",
       "      <td>51.786041</td>\n",
       "      <td>66.434969</td>\n",
       "      <td>-46.842632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1           2          3           4           5     \n",
       "0  77.973457   44.453701 -173.219830  -4.410628   75.493393   41.393043  \\\n",
       "1  -4.109793    2.340805  -21.485545 -59.833237   25.337529  -48.522722   \n",
       "2 -46.598287   26.098580  -58.658402  62.726847   51.278867  -51.657226   \n",
       "3  35.360342   60.163725  -27.901776 -53.709725  -35.968431   24.307124   \n",
       "4  34.598532 -100.970966 -192.003554  32.115457  105.654387 -244.451265   \n",
       "\n",
       "         6           7           8          9    ...        290        291   \n",
       "0 -41.580649   84.183355 -278.957716  23.654842  ...  26.416055 -84.681734  \\\n",
       "1  20.918352   88.404150  -18.247384   0.922639  ...  18.760534  28.946899   \n",
       "2  61.282318  218.317215 -145.487613  51.764659  ...  16.600708  10.613136   \n",
       "3  47.461727   82.214472  -20.191026   8.705730  ...  40.188845 -64.445338   \n",
       "4   0.215317  295.835997  140.651610 -64.710206  ...  53.694146 -93.960855   \n",
       "\n",
       "          292        293         294         295         296         297   \n",
       "0  -88.431000  37.586479    4.812845  -50.764075  -21.439394  -47.322849  \\\n",
       "1   40.868272  41.995686  -16.039801   -6.515951   17.120571    4.826173   \n",
       "2   44.777887  13.170672  -40.014347   90.090577  110.328283 -130.407567   \n",
       "3    3.300989  -3.460388   -5.688108  -39.654131   -8.501600   41.287611   \n",
       "4  280.227130 -71.913438 -244.190637  108.494457  354.313131   51.786041   \n",
       "\n",
       "          298        299  \n",
       "0 -114.611610  -0.633502  \n",
       "1  -36.251713  -4.849846  \n",
       "2  -71.836666  49.603967  \n",
       "3  -22.826380  72.295970  \n",
       "4   66.434969 -46.842632  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_tfidfavgw2v_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_features_headers = []\n",
    "q2_features_headers = []\n",
    "for i in range(300):\n",
    "    q1_features_headers.append(\"q1_feat_\"+str(i+1))\n",
    "    q2_features_headers.append(\"q2_feat_\"+str(i+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_feat_1</th>\n",
       "      <th>q1_feat_2</th>\n",
       "      <th>q1_feat_3</th>\n",
       "      <th>q1_feat_4</th>\n",
       "      <th>q1_feat_5</th>\n",
       "      <th>q1_feat_6</th>\n",
       "      <th>q1_feat_7</th>\n",
       "      <th>q1_feat_8</th>\n",
       "      <th>q1_feat_9</th>\n",
       "      <th>q1_feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_feat_291</th>\n",
       "      <th>q1_feat_292</th>\n",
       "      <th>q1_feat_293</th>\n",
       "      <th>q1_feat_294</th>\n",
       "      <th>q1_feat_295</th>\n",
       "      <th>q1_feat_296</th>\n",
       "      <th>q1_feat_297</th>\n",
       "      <th>q1_feat_298</th>\n",
       "      <th>q1_feat_299</th>\n",
       "      <th>q1_feat_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.973457</td>\n",
       "      <td>44.453701</td>\n",
       "      <td>-173.219830</td>\n",
       "      <td>-4.410628</td>\n",
       "      <td>75.493393</td>\n",
       "      <td>41.393043</td>\n",
       "      <td>-41.580649</td>\n",
       "      <td>84.183355</td>\n",
       "      <td>-278.957716</td>\n",
       "      <td>23.654842</td>\n",
       "      <td>...</td>\n",
       "      <td>26.416055</td>\n",
       "      <td>-84.681734</td>\n",
       "      <td>-88.431000</td>\n",
       "      <td>37.586479</td>\n",
       "      <td>4.812845</td>\n",
       "      <td>-50.764075</td>\n",
       "      <td>-21.439394</td>\n",
       "      <td>-47.322849</td>\n",
       "      <td>-114.611610</td>\n",
       "      <td>-0.633502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.109793</td>\n",
       "      <td>2.340805</td>\n",
       "      <td>-21.485545</td>\n",
       "      <td>-59.833237</td>\n",
       "      <td>25.337529</td>\n",
       "      <td>-48.522722</td>\n",
       "      <td>20.918352</td>\n",
       "      <td>88.404150</td>\n",
       "      <td>-18.247384</td>\n",
       "      <td>0.922639</td>\n",
       "      <td>...</td>\n",
       "      <td>18.760534</td>\n",
       "      <td>28.946899</td>\n",
       "      <td>40.868272</td>\n",
       "      <td>41.995686</td>\n",
       "      <td>-16.039801</td>\n",
       "      <td>-6.515951</td>\n",
       "      <td>17.120571</td>\n",
       "      <td>4.826173</td>\n",
       "      <td>-36.251713</td>\n",
       "      <td>-4.849846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-46.598287</td>\n",
       "      <td>26.098580</td>\n",
       "      <td>-58.658402</td>\n",
       "      <td>62.726847</td>\n",
       "      <td>51.278867</td>\n",
       "      <td>-51.657226</td>\n",
       "      <td>61.282318</td>\n",
       "      <td>218.317215</td>\n",
       "      <td>-145.487613</td>\n",
       "      <td>51.764659</td>\n",
       "      <td>...</td>\n",
       "      <td>16.600708</td>\n",
       "      <td>10.613136</td>\n",
       "      <td>44.777887</td>\n",
       "      <td>13.170672</td>\n",
       "      <td>-40.014347</td>\n",
       "      <td>90.090577</td>\n",
       "      <td>110.328283</td>\n",
       "      <td>-130.407567</td>\n",
       "      <td>-71.836666</td>\n",
       "      <td>49.603967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.360342</td>\n",
       "      <td>60.163725</td>\n",
       "      <td>-27.901776</td>\n",
       "      <td>-53.709725</td>\n",
       "      <td>-35.968431</td>\n",
       "      <td>24.307124</td>\n",
       "      <td>47.461727</td>\n",
       "      <td>82.214472</td>\n",
       "      <td>-20.191026</td>\n",
       "      <td>8.705730</td>\n",
       "      <td>...</td>\n",
       "      <td>40.188845</td>\n",
       "      <td>-64.445338</td>\n",
       "      <td>3.300989</td>\n",
       "      <td>-3.460388</td>\n",
       "      <td>-5.688108</td>\n",
       "      <td>-39.654131</td>\n",
       "      <td>-8.501600</td>\n",
       "      <td>41.287611</td>\n",
       "      <td>-22.826380</td>\n",
       "      <td>72.295970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.598532</td>\n",
       "      <td>-100.970966</td>\n",
       "      <td>-192.003554</td>\n",
       "      <td>32.115457</td>\n",
       "      <td>105.654387</td>\n",
       "      <td>-244.451265</td>\n",
       "      <td>0.215317</td>\n",
       "      <td>295.835997</td>\n",
       "      <td>140.651610</td>\n",
       "      <td>-64.710206</td>\n",
       "      <td>...</td>\n",
       "      <td>53.694146</td>\n",
       "      <td>-93.960855</td>\n",
       "      <td>280.227130</td>\n",
       "      <td>-71.913438</td>\n",
       "      <td>-244.190637</td>\n",
       "      <td>108.494457</td>\n",
       "      <td>354.313131</td>\n",
       "      <td>51.786041</td>\n",
       "      <td>66.434969</td>\n",
       "      <td>-46.842632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q1_feat_1   q1_feat_2   q1_feat_3  q1_feat_4   q1_feat_5   q1_feat_6   \n",
       "0  77.973457   44.453701 -173.219830  -4.410628   75.493393   41.393043  \\\n",
       "1  -4.109793    2.340805  -21.485545 -59.833237   25.337529  -48.522722   \n",
       "2 -46.598287   26.098580  -58.658402  62.726847   51.278867  -51.657226   \n",
       "3  35.360342   60.163725  -27.901776 -53.709725  -35.968431   24.307124   \n",
       "4  34.598532 -100.970966 -192.003554  32.115457  105.654387 -244.451265   \n",
       "\n",
       "   q1_feat_7   q1_feat_8   q1_feat_9  q1_feat_10  ...  q1_feat_291   \n",
       "0 -41.580649   84.183355 -278.957716   23.654842  ...    26.416055  \\\n",
       "1  20.918352   88.404150  -18.247384    0.922639  ...    18.760534   \n",
       "2  61.282318  218.317215 -145.487613   51.764659  ...    16.600708   \n",
       "3  47.461727   82.214472  -20.191026    8.705730  ...    40.188845   \n",
       "4   0.215317  295.835997  140.651610  -64.710206  ...    53.694146   \n",
       "\n",
       "   q1_feat_292  q1_feat_293  q1_feat_294  q1_feat_295  q1_feat_296   \n",
       "0   -84.681734   -88.431000    37.586479     4.812845   -50.764075  \\\n",
       "1    28.946899    40.868272    41.995686   -16.039801    -6.515951   \n",
       "2    10.613136    44.777887    13.170672   -40.014347    90.090577   \n",
       "3   -64.445338     3.300989    -3.460388    -5.688108   -39.654131   \n",
       "4   -93.960855   280.227130   -71.913438  -244.190637   108.494457   \n",
       "\n",
       "   q1_feat_297  q1_feat_298  q1_feat_299  q1_feat_300  \n",
       "0   -21.439394   -47.322849  -114.611610    -0.633502  \n",
       "1    17.120571     4.826173   -36.251713    -4.849846  \n",
       "2   110.328283  -130.407567   -71.836666    49.603967  \n",
       "3    -8.501600    41.287611   -22.826380    72.295970  \n",
       "4   354.313131    51.786041    66.434969   -46.842632  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_tfidfavgw2v_features.columns = q1_features_headers\n",
    "q1_tfidfavgw2v_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q2_feat_1</th>\n",
       "      <th>q2_feat_2</th>\n",
       "      <th>q2_feat_3</th>\n",
       "      <th>q2_feat_4</th>\n",
       "      <th>q2_feat_5</th>\n",
       "      <th>q2_feat_6</th>\n",
       "      <th>q2_feat_7</th>\n",
       "      <th>q2_feat_8</th>\n",
       "      <th>q2_feat_9</th>\n",
       "      <th>q2_feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>q2_feat_291</th>\n",
       "      <th>q2_feat_292</th>\n",
       "      <th>q2_feat_293</th>\n",
       "      <th>q2_feat_294</th>\n",
       "      <th>q2_feat_295</th>\n",
       "      <th>q2_feat_296</th>\n",
       "      <th>q2_feat_297</th>\n",
       "      <th>q2_feat_298</th>\n",
       "      <th>q2_feat_299</th>\n",
       "      <th>q2_feat_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.057064</td>\n",
       "      <td>52.681846</td>\n",
       "      <td>-169.935391</td>\n",
       "      <td>-3.243233</td>\n",
       "      <td>53.222714</td>\n",
       "      <td>59.307491</td>\n",
       "      <td>-58.016089</td>\n",
       "      <td>84.049185</td>\n",
       "      <td>-274.510704</td>\n",
       "      <td>30.463488</td>\n",
       "      <td>...</td>\n",
       "      <td>13.756101</td>\n",
       "      <td>-75.554456</td>\n",
       "      <td>-83.103968</td>\n",
       "      <td>43.434313</td>\n",
       "      <td>26.063637</td>\n",
       "      <td>-52.797590</td>\n",
       "      <td>-17.386567</td>\n",
       "      <td>-35.062074</td>\n",
       "      <td>-102.498085</td>\n",
       "      <td>-11.970820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.991234</td>\n",
       "      <td>18.972404</td>\n",
       "      <td>-104.731602</td>\n",
       "      <td>-26.501467</td>\n",
       "      <td>62.586380</td>\n",
       "      <td>36.496242</td>\n",
       "      <td>37.162907</td>\n",
       "      <td>132.718870</td>\n",
       "      <td>60.264024</td>\n",
       "      <td>-1.595595</td>\n",
       "      <td>...</td>\n",
       "      <td>58.229712</td>\n",
       "      <td>59.083779</td>\n",
       "      <td>20.090896</td>\n",
       "      <td>9.392637</td>\n",
       "      <td>-76.729526</td>\n",
       "      <td>42.790878</td>\n",
       "      <td>-84.178477</td>\n",
       "      <td>41.360930</td>\n",
       "      <td>-90.049836</td>\n",
       "      <td>65.292126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.054749</td>\n",
       "      <td>8.966757</td>\n",
       "      <td>-32.669609</td>\n",
       "      <td>64.714678</td>\n",
       "      <td>70.892380</td>\n",
       "      <td>-41.697565</td>\n",
       "      <td>32.054564</td>\n",
       "      <td>218.153316</td>\n",
       "      <td>-99.107224</td>\n",
       "      <td>12.227849</td>\n",
       "      <td>...</td>\n",
       "      <td>15.184921</td>\n",
       "      <td>27.294229</td>\n",
       "      <td>30.089786</td>\n",
       "      <td>-1.801036</td>\n",
       "      <td>-60.964952</td>\n",
       "      <td>89.953825</td>\n",
       "      <td>121.342901</td>\n",
       "      <td>-75.809698</td>\n",
       "      <td>-74.579956</td>\n",
       "      <td>76.083279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-67.871643</td>\n",
       "      <td>-1.291338</td>\n",
       "      <td>-28.803573</td>\n",
       "      <td>-6.979753</td>\n",
       "      <td>117.594441</td>\n",
       "      <td>34.824081</td>\n",
       "      <td>-1.183070</td>\n",
       "      <td>65.186494</td>\n",
       "      <td>-35.391374</td>\n",
       "      <td>-34.799505</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.915117</td>\n",
       "      <td>-33.911907</td>\n",
       "      <td>-27.728121</td>\n",
       "      <td>-14.628237</td>\n",
       "      <td>-42.692830</td>\n",
       "      <td>20.241970</td>\n",
       "      <td>-47.275902</td>\n",
       "      <td>-47.144042</td>\n",
       "      <td>3.134417</td>\n",
       "      <td>-20.761216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.763654</td>\n",
       "      <td>6.005122</td>\n",
       "      <td>-111.848332</td>\n",
       "      <td>17.465527</td>\n",
       "      <td>62.162129</td>\n",
       "      <td>-88.357357</td>\n",
       "      <td>-31.264316</td>\n",
       "      <td>156.222801</td>\n",
       "      <td>-70.721046</td>\n",
       "      <td>58.084528</td>\n",
       "      <td>...</td>\n",
       "      <td>87.066215</td>\n",
       "      <td>-51.738576</td>\n",
       "      <td>95.601252</td>\n",
       "      <td>-65.619994</td>\n",
       "      <td>-139.510619</td>\n",
       "      <td>-99.868408</td>\n",
       "      <td>5.537125</td>\n",
       "      <td>-11.700133</td>\n",
       "      <td>-26.135739</td>\n",
       "      <td>16.903017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   q2_feat_1  q2_feat_2   q2_feat_3  q2_feat_4   q2_feat_5  q2_feat_6   \n",
       "0  79.057064  52.681846 -169.935391  -3.243233   53.222714  59.307491  \\\n",
       "1 -73.991234  18.972404 -104.731602 -26.501467   62.586380  36.496242   \n",
       "2  19.054749   8.966757  -32.669609  64.714678   70.892380 -41.697565   \n",
       "3 -67.871643  -1.291338  -28.803573  -6.979753  117.594441  34.824081   \n",
       "4  10.763654   6.005122 -111.848332  17.465527   62.162129 -88.357357   \n",
       "\n",
       "   q2_feat_7   q2_feat_8   q2_feat_9  q2_feat_10  ...  q2_feat_291   \n",
       "0 -58.016089   84.049185 -274.510704   30.463488  ...    13.756101  \\\n",
       "1  37.162907  132.718870   60.264024   -1.595595  ...    58.229712   \n",
       "2  32.054564  218.153316  -99.107224   12.227849  ...    15.184921   \n",
       "3  -1.183070   65.186494  -35.391374  -34.799505  ...   -13.915117   \n",
       "4 -31.264316  156.222801  -70.721046   58.084528  ...    87.066215   \n",
       "\n",
       "   q2_feat_292  q2_feat_293  q2_feat_294  q2_feat_295  q2_feat_296   \n",
       "0   -75.554456   -83.103968    43.434313    26.063637   -52.797590  \\\n",
       "1    59.083779    20.090896     9.392637   -76.729526    42.790878   \n",
       "2    27.294229    30.089786    -1.801036   -60.964952    89.953825   \n",
       "3   -33.911907   -27.728121   -14.628237   -42.692830    20.241970   \n",
       "4   -51.738576    95.601252   -65.619994  -139.510619   -99.868408   \n",
       "\n",
       "   q2_feat_297  q2_feat_298  q2_feat_299  q2_feat_300  \n",
       "0   -17.386567   -35.062074  -102.498085   -11.970820  \n",
       "1   -84.178477    41.360930   -90.049836    65.292126  \n",
       "2   121.342901   -75.809698   -74.579956    76.083279  \n",
       "3   -47.275902   -47.144042     3.134417   -20.761216  \n",
       "4     5.537125   -11.700133   -26.135739    16.903017  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_tfidfavgw2v_features.columns = q2_features_headers\n",
    "q2_tfidfavgw2v_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1_tfidfavgw2v_features exported!\n",
      "Time taken: 0:03:06.010511\n",
      "\n",
      "q2_tfidfavgw2v_features exported!\n",
      "Time taken: 0:03:10.378680\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "q1_tfidfavgw2v_features.to_csv('../data/processed/q1_tfidfavgw2v_features.csv', index=False)\n",
    "print('q1_tfidfavgw2v_features exported!\\nTime taken: {0}'.format(datetime.now()-start))\n",
    "\n",
    "start = datetime.now()\n",
    "q2_tfidfavgw2v_features.to_csv('../data/processed/q2_tfidfavgw2v_features.csv', index=False)\n",
    "print('\\nq2_tfidfavgw2v_features exported!\\nTime taken: {0}'.format(datetime.now()-start))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Combine all features\n",
    "\n",
    "We have below DataFrames with different features<br>\n",
    "1. raw_data_featurized - This has id, qid, qid2, question1, question2, is_duplicate and 16 new features\n",
    "2. processed_data_featurized - This has id, qid, qid2, question1, question2, is_duplicate and 11 new features\n",
    "3. q1_tfidfavgw2v_features - This has 300 features derived from question1\n",
    "4. q2_tfidfavgw2v_features - This has 300 features derived from question2<br><br>\n",
    "\n",
    "So, in total, we have 627 new features. Lets combine all these features into single DataFrame and dump it into sqlite3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw_data_featurized: (404290, 22)\n",
      "Shape of processed_data_featurized: (404290, 17)\n",
      "Shape of q1_tfidfavgw2v_features: (404290, 300)\n",
      "Shape of q2_tfidfavgw2v_features: (404290, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of raw_data_featurized: {0}\".format(raw_data_featurized.shape))\n",
    "print(\"Shape of processed_data_featurized: {0}\".format(processed_data_featurized.shape))\n",
    "print(\"Shape of q1_tfidfavgw2v_features: {0}\".format(q1_tfidfavgw2v_features.shape))\n",
    "print(\"Shape of q2_tfidfavgw2v_features: {0}\".format(q2_tfidfavgw2v_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all features\n",
      "Operation complete.\n",
      "Time taken: 0:00:00.894343\n",
      "\n",
      "Shape of processed_final_features: (404290, 633)\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(\"Combining all features\")\n",
    "processed_final_features = pd.concat([raw_data_featurized, processed_data_featurized.iloc[:,6:], q1_tfidfavgw2v_features, q2_tfidfavgw2v_features], axis=1)\n",
    "print(\"Operation complete.\\nTime taken: {0}\".format(datetime.now()-start))\n",
    "print(\"\\nShape of processed_final_features: {0}\".format(processed_final_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_frequency</th>\n",
       "      <th>q2_frequency</th>\n",
       "      <th>q1_length</th>\n",
       "      <th>q2_length</th>\n",
       "      <th>...</th>\n",
       "      <th>q2_feat_291</th>\n",
       "      <th>q2_feat_292</th>\n",
       "      <th>q2_feat_293</th>\n",
       "      <th>q2_feat_294</th>\n",
       "      <th>q2_feat_295</th>\n",
       "      <th>q2_feat_296</th>\n",
       "      <th>q2_feat_297</th>\n",
       "      <th>q2_feat_298</th>\n",
       "      <th>q2_feat_299</th>\n",
       "      <th>q2_feat_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.756101</td>\n",
       "      <td>-75.554456</td>\n",
       "      <td>-83.103968</td>\n",
       "      <td>43.434313</td>\n",
       "      <td>26.063637</td>\n",
       "      <td>-52.797590</td>\n",
       "      <td>-17.386567</td>\n",
       "      <td>-35.062074</td>\n",
       "      <td>-102.498085</td>\n",
       "      <td>-11.970820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.229712</td>\n",
       "      <td>59.083779</td>\n",
       "      <td>20.090896</td>\n",
       "      <td>9.392637</td>\n",
       "      <td>-76.729526</td>\n",
       "      <td>42.790878</td>\n",
       "      <td>-84.178477</td>\n",
       "      <td>41.360930</td>\n",
       "      <td>-90.049836</td>\n",
       "      <td>65.292126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.184921</td>\n",
       "      <td>27.294229</td>\n",
       "      <td>30.089786</td>\n",
       "      <td>-1.801036</td>\n",
       "      <td>-60.964952</td>\n",
       "      <td>89.953825</td>\n",
       "      <td>121.342901</td>\n",
       "      <td>-75.809698</td>\n",
       "      <td>-74.579956</td>\n",
       "      <td>76.083279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.915117</td>\n",
       "      <td>-33.911907</td>\n",
       "      <td>-27.728121</td>\n",
       "      <td>-14.628237</td>\n",
       "      <td>-42.692830</td>\n",
       "      <td>20.241970</td>\n",
       "      <td>-47.275902</td>\n",
       "      <td>-47.144042</td>\n",
       "      <td>3.134417</td>\n",
       "      <td>-20.761216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.066215</td>\n",
       "      <td>-51.738576</td>\n",
       "      <td>95.601252</td>\n",
       "      <td>-65.619994</td>\n",
       "      <td>-139.510619</td>\n",
       "      <td>-99.868408</td>\n",
       "      <td>5.537125</td>\n",
       "      <td>-11.700133</td>\n",
       "      <td>-26.135739</td>\n",
       "      <td>16.903017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1   \n",
       "0   0     1     2  What is the step by step guide to invest in sh...  \\\n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate   \n",
       "0  What is the step by step guide to invest in sh...             0  \\\n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "   q1_frequency  q2_frequency  q1_length  q2_length  ...  q2_feat_291   \n",
       "0             1             1       66.0       57.0  ...    13.756101  \\\n",
       "1             4             1       51.0       88.0  ...    58.229712   \n",
       "2             1             1       73.0       59.0  ...    15.184921   \n",
       "3             1             1       50.0       65.0  ...   -13.915117   \n",
       "4             3             1       76.0       39.0  ...    87.066215   \n",
       "\n",
       "   q2_feat_292  q2_feat_293  q2_feat_294  q2_feat_295  q2_feat_296   \n",
       "0   -75.554456   -83.103968    43.434313    26.063637   -52.797590  \\\n",
       "1    59.083779    20.090896     9.392637   -76.729526    42.790878   \n",
       "2    27.294229    30.089786    -1.801036   -60.964952    89.953825   \n",
       "3   -33.911907   -27.728121   -14.628237   -42.692830    20.241970   \n",
       "4   -51.738576    95.601252   -65.619994  -139.510619   -99.868408   \n",
       "\n",
       "   q2_feat_297  q2_feat_298  q2_feat_299  q2_feat_300  \n",
       "0   -17.386567   -35.062074  -102.498085   -11.970820  \n",
       "1   -84.178477    41.360930   -90.049836    65.292126  \n",
       "2   121.342901   -75.809698   -74.579956    76.083279  \n",
       "3   -47.275902   -47.144042     3.134417   -20.761216  \n",
       "4     5.537125   -11.700133   -26.135739    16.903017  \n",
       "\n",
       "[5 rows x 633 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_final_features.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_final_features exported!\n",
      "Time taken: 0:06:36.372394\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "processed_final_features.to_csv('../data/processed/processed_final_features.csv', index=False)\n",
    "print('processed_final_features exported!\\nTime taken: {0}'.format(datetime.now()-start))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Store the final features in sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to SQLite.\n",
      "Time taken: 1:21:49.501035\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "disk_engine = create_engine('sqlite:///train.db')\n",
    "processed_final_features.to_sql('train_data', disk_engine, if_exists='append')\n",
    "print(\"Wrote to SQLite.\\nTime taken: {0}\".format(datetime.now() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
